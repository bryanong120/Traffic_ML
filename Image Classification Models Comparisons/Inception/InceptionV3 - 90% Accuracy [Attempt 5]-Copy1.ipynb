{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "NU-1tQQA2aCI",
    "outputId": "4aa332bb-c908-46dd-9fc6-e01ae55b72fb",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import splitfolders\n",
    "import shutil\n",
    "import random\n",
    "import csv\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "main_dir = os.path.normpath(os.getcwd() + os.sep + os.pardir + os.sep + os.pardir)\n",
    "dataset_dir = os.path.join(main_dir, 'image_dataset')\n",
    "dataset_dir_2 = os.path.join(main_dir, 'image_dataset_2')\n",
    "train_dir = os.path.join(dataset_dir_2, 'train')\n",
    "val_dir = os.path.join(dataset_dir_2, 'val')\n",
    "test_dir = os.path.join(dataset_dir_2, 'test')\n",
    "\n",
    "# splits the image dataset into 64% training, 16% validation, and 20% test sets into a new directory\n",
    "def split_images():\n",
    "    randNum = random.randint(0, 1337)\n",
    "    if os.path.exists(dataset_dir_2):\n",
    "        shutil.rmtree(dataset_dir_2)\n",
    "    if not os.path.exists(dataset_dir_2):\n",
    "        os.mkdir(dataset_dir_2)\n",
    "    splitfolders.ratio(dataset_dir, output=dataset_dir_2, \n",
    "                       seed=randNum, ratio=(.64, .16, .2), \n",
    "                       group_prefix=None)\n",
    "    return \"Dataset splitting completed\"\n",
    "\n",
    "# saves the training record into csv file for comparison\n",
    "def save_training_record(model_name, attempt):\n",
    "    csv_path = os.path.join(main_dir, 'imageClassificationsComparisons.csv')\n",
    "    csv_file = open(csv_path, 'a', newline='')\n",
    "    wr = csv.writer(csv_file)\n",
    "    wr.writerow([model_name, attempt, initial_epochs, earlystopping.stopped_epoch+1-initial_epochs, \n",
    "                 training_time, loss1*100, accuracy1*100, 60*accuracy1])\n",
    "    csv_file.close()\n",
    "    return \"record saved in csv file successfully\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 291 files [00:00, 610.06 files/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dataset splitting completed'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Splits the dataset\n",
    "split_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 files belonging to 2 classes.\n",
      "Found 185 images belonging to 2 classes.\n",
      "Found 46 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255., rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2,shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(test_dir,\n",
    "                                                           batch_size=60,\n",
    "                                                          image_size=IMG_SIZE)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n",
    "validation_generator = test_datagen.flow_from_directory(val_dir, batch_size = 20, class_mode = 'binary', target_size = (224, 224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for images, labels in train_dataset.take(1):\n",
    "  for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the Dataset For Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "for image, _ in train_dataset.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[0]\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescaling Pixel Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Base Model from Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model InceptionV3\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = InceptionV3(input_shape=IMG_SHAPE, include_top=False, weights='imagenet')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Freeze The Convolutional Base\n",
    "#It is important to freeze the convolutional base before you compile and train the model. \n",
    "#Freezing (by setting layer.trainable = False) prevents the weights in a given layer from \n",
    "#being updated during training. MobileNet V2 has many layers, so setting the entire model's \n",
    "#trainable flag to False will freeze all of them.\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Important note about BatchNormalization layers\n",
    "\n",
    "#Many models contain `tf.keras.layers.BatchNormalization` layers. This layer is a special case and precautions \n",
    "#should be taken in the context of fine-tuning, as shown later in this tutorial. \n",
    "\n",
    "#When you set `layer.trainable = False`, the `BatchNormalization` layer will run in inference mode, and will \n",
    "#not update its mean and variance statistics. \n",
    "\n",
    "#When you unfreeze a model that contains BatchNormalization layers in order to do fine-tuning, you should keep \n",
    "#the BatchNormalization layers in inference mode by passing `training = False` when calling the base model. \n",
    "#Otherwise, the updates applied to the non-trainable weights will destroy what the model has learned.\n",
    "\n",
    "#For more details, see the [Transfer learning guide](https://www.tensorflow.org/guide/keras/transfer_learning).\n",
    "\n",
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add a classification head\n",
    "\n",
    "#To generate predictions from the block of features, average over the spatial `5x5` spatial locations, using a `tf.keras.layers.GlobalAveragePooling2D` layer to convert the features to  a single 1280-element vector per image.\n",
    "\n",
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Dense layer is added to convert features into a single predictions per image, \n",
    "# in which positive numbers predict class 1 (Normal Roads) and negative numbers predict\n",
    "# no activation is required as predictions will be a logit or raw prediction value\n",
    "\n",
    "prediction_layer = tf.keras.layers.Dense(1)\n",
    "prediction_batch = prediction_layer(feature_batch_average)\n",
    "print(prediction_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build a model by chaining together the data augmentation, rescaling, `base_model` and feature extractor \n",
    "#layers using the [Keras Functional API](https://www.tensorflow.org/guide/keras/functional). As previously mentioned, \n",
    "#use `training=False` as our model contains a `BatchNormalization` layer.\n",
    "\n",
    "\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "x = tf.keras.layers.Flatten()(base_model.output)\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x)\n",
    "x = tf.keras.layers.Dropout(0.2)(x)\n",
    "\n",
    "# Add a final sigmoid layer with 1 node for classification output\n",
    "x = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(base_model.input, x)\n",
    "\n",
    "model.compile(optimizer = RMSprop(learning_rate=0.0001), loss = 'binary_crossentropy', metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model\n",
    "\n",
    "#Compile the model before training it. Since there are two classes, use the `tf.keras.losses.BinaryCrossentropy` \n",
    "#loss with `from_logits=True` since the model provides a linear output.\n",
    "\n",
    "base_learning_rate = 0.00012\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=base_learning_rate),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#The 2.5 million parameters in MobileNet are frozen, but there are 1.2 thousand _trainable_ parameters in the Dense layer. \n",
    "#These are divided between two `tf.Variable` objects, the weights and biases.\n",
    "\n",
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 27s 2s/step - loss: 10.5684 - acc: 0.5730 - val_loss: 1.3472 - val_acc: 0.4565\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.6125 - acc: 0.7622 - val_loss: 0.8984 - val_acc: 0.6957\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.7297 - acc: 0.7243 - val_loss: 2.4698 - val_acc: 0.6522\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.5034 - acc: 0.8486 - val_loss: 0.4435 - val_acc: 0.8478\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.7445 - acc: 0.7838 - val_loss: 0.8903 - val_acc: 0.8043\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.5547 - acc: 0.8108 - val_loss: 0.8414 - val_acc: 0.8261\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.5252 - acc: 0.8324 - val_loss: 0.2631 - val_acc: 0.8696\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.4592 - acc: 0.8649 - val_loss: 0.4095 - val_acc: 0.8478\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.5147 - acc: 0.8162 - val_loss: 1.0653 - val_acc: 0.6957\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.3487 - acc: 0.8541 - val_loss: 0.4536 - val_acc: 0.8696\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.5165 - acc: 0.8378 - val_loss: 0.3600 - val_acc: 0.8913\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.3523 - acc: 0.8865 - val_loss: 0.4799 - val_acc: 0.8696\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.3259 - acc: 0.8757 - val_loss: 0.2134 - val_acc: 0.8913\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.3376 - acc: 0.8757 - val_loss: 0.3743 - val_acc: 0.9130\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.2204 - acc: 0.9027 - val_loss: 0.4088 - val_acc: 0.8696\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.3715 - acc: 0.8432 - val_loss: 0.5039 - val_acc: 0.8478\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.3549 - acc: 0.8486 - val_loss: 0.3879 - val_acc: 0.8696\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1122 - acc: 0.9568 - val_loss: 0.5534 - val_acc: 0.8478\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.4345 - acc: 0.8703 - val_loss: 0.3124 - val_acc: 0.8696\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2373 - acc: 0.9027 - val_loss: 0.2817 - val_acc: 0.9130\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.1900 - acc: 0.9297 - val_loss: 0.5851 - val_acc: 0.8696\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.2851 - acc: 0.9027 - val_loss: 0.3157 - val_acc: 0.8913\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.3806 - acc: 0.8649 - val_loss: 0.7373 - val_acc: 0.8478\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.2754 - acc: 0.9189 - val_loss: 0.3068 - val_acc: 0.9348\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.2458 - acc: 0.9189 - val_loss: 0.3106 - val_acc: 0.8696\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2399 - acc: 0.9189 - val_loss: 0.5477 - val_acc: 0.8913\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.1529 - acc: 0.9514 - val_loss: 0.5696 - val_acc: 0.8913\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.1822 - acc: 0.9297 - val_loss: 0.5707 - val_acc: 0.8913\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.4062 - acc: 0.8919 - val_loss: 0.2845 - val_acc: 0.8913\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2142 - acc: 0.9243 - val_loss: 0.4608 - val_acc: 0.8913\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.3414 - acc: 0.8865 - val_loss: 0.4204 - val_acc: 0.9130\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.1498 - acc: 0.9297 - val_loss: 0.2814 - val_acc: 0.8913\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.2918 - acc: 0.8973 - val_loss: 0.4859 - val_acc: 0.9130\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.3095 - acc: 0.9027 - val_loss: 0.7033 - val_acc: 0.8478\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 19s 2s/step - loss: 0.2313 - acc: 0.8973 - val_loss: 0.5025 - val_acc: 0.8913\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.2995 - acc: 0.8973 - val_loss: 0.3145 - val_acc: 0.8913\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 20s 2s/step - loss: 0.1391 - acc: 0.9459 - val_loss: 0.4133 - val_acc: 0.8913\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.0649 - acc: 0.9622 - val_loss: 0.3759 - val_acc: 0.9130\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.1460 - acc: 0.9405 - val_loss: 0.4557 - val_acc: 0.8478\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.1992 - acc: 0.9351 - val_loss: 0.3286 - val_acc: 0.8913\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.1436 - acc: 0.9568 - val_loss: 0.3485 - val_acc: 0.9130\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.1174 - acc: 0.9459 - val_loss: 0.7671 - val_acc: 0.8478\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.4166 - acc: 0.8649 - val_loss: 0.5736 - val_acc: 0.8696\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.3078 - acc: 0.9027 - val_loss: 0.3278 - val_acc: 0.8913\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.2636 - acc: 0.8865 - val_loss: 0.3301 - val_acc: 0.9130\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.0871 - acc: 0.9784 - val_loss: 0.5082 - val_acc: 0.8696\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.2492 - acc: 0.9027 - val_loss: 0.4622 - val_acc: 0.9130\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.1450 - acc: 0.9459 - val_loss: 0.3333 - val_acc: 0.9130\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.1825 - acc: 0.9568 - val_loss: 0.3199 - val_acc: 0.9348\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.1754 - acc: 0.9189 - val_loss: 0.6699 - val_acc: 0.8043\n"
     ]
    }
   ],
   "source": [
    "### Train the model with earlystopping callbacks to avoid overfitting the model. \n",
    "# Usually earlystopping will be called in the Fine Tuning phase instead of Feature Extraction\n",
    "\n",
    "from keras import callbacks\n",
    "earlystopping = callbacks.EarlyStopping(monitor =\"val_loss\", \n",
    "                                        mode =\"min\", patience = 5, \n",
    "                                        restore_best_weights = True)\n",
    "\n",
    "initial_epochs = 50\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "inc_history = model.fit(train_generator, validation_data = validation_generator, epochs = 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the feature extraction experiment, you were only training a few layers on top of an MobileNetV2 base model. \n",
    "#The weights of the pre-trained network were **not** updated during training.\n",
    "\n",
    "#One way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the \n",
    "#pre-trained model alongside the training of the classifier you added. The training process will force the weights \n",
    "#to be tuned from generic feature maps to features associated specifically with the dataset.\n",
    "\n",
    "#Note: This should only be attempted after you have trained the top-level classifier with the pre-trained model set \n",
    "#to non-trainable. If you add a randomly initialized classifier on top of a pre-trained model and attempt to train \n",
    "#all layers jointly, the magnitude of the gradient updates will be too large (due to the random weights from the classifier) \n",
    "#and your pre-trained model will forget what it has learned.\n",
    "\n",
    "#Also, you should try to fine-tune a small number of top layers rather than the whole MobileNet model. In most convolutional \n",
    "#networks, the higher up a layer is, the more specialized it is. The first few layers learn very simple and generic features \n",
    "#that generalize to almost all types of images. As you go higher up, the features are increasingly more specific to the dataset \n",
    "#on which the model was trained. The goal of fine-tuning is to adapt these specialized features to work with the new dataset, \n",
    "#rather than overwrite the generic learning.\n",
    "\n",
    "### Un-freeze the top layers of the model\n",
    "\n",
    "\n",
    "#All you need to do is unfreeze the `base_model` and set the bottom layers to be un-trainable. Then, you should recompile the \n",
    "#model (necessary for these changes to take effect), and resume training.\n",
    "\n",
    "base_model.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look to see how many layers are in the base model\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))\n",
    "\n",
    "# Fine-tune from this layer onwards\n",
    "fine_tune_at = 5\n",
    "\n",
    "# Freeze all the layers before the `fine_tune_at` layer\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "  layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compile the model\n",
    "\n",
    "#As you are training a much larger model and want to readapt the pretrained weights, it is important to use a lower \n",
    "#learning rate at this stage. Otherwise, your model could overfit very quickly.\n",
    "ft_learning_rate = 0.000008\n",
    "\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer = tf.keras.optimizers.RMSprop(learning_rate=ft_learning_rate),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "len(model.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Continue training the model\n",
    "\n",
    "#If you trained to convergence earlier, this step will improve your accuracy by a few percentage points.\n",
    "\n",
    "fine_tune_epochs = 50\n",
    "total_epochs =  initial_epochs + fine_tune_epochs\n",
    "\n",
    "history_fine = model.fit(train_dataset,\n",
    "                         epochs=total_epochs,\n",
    "                         initial_epoch=(history.epoch[-1]+1),\n",
    "                         validation_data=validation_dataset,\n",
    "                         callbacks =[earlystopping])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at the learning curves of the training and validation accuracy/loss when fine-tuning the last few \n",
    "#layers of the MobileNetV2 base model and training the classifier on top of it. The validation loss is much higher than the \n",
    "#training loss, so you may get some overfitting.\n",
    "\n",
    "#You may also get some overfitting as the new training set is relatively small and similar to the original MobileNetV2 datasets.\n",
    "\n",
    "training_time = time.time() - start_time\n",
    "print(\"--- %s seconds taken to train model ---\" % (training_time))\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "acc += history_fine.history['accuracy']\n",
    "\n",
    "val_acc = history.history['val_accuracy']\n",
    "val_acc += history_fine.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "loss += history_fine.history['loss']\n",
    "\n",
    "val_loss = history.history['val_loss']\n",
    "val_loss += history_fine.history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.ylim([0.3, 1])\n",
    "plt.plot([initial_epochs+1,initial_epochs+1],\n",
    "          plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.ylim([0, 1.0])\n",
    "plt.plot([initial_epochs+1,initial_epochs+1],\n",
    "         plt.ylim(), label='Start Fine Tuning')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step - loss: 106.0931 - acc: 0.3667\n",
      "The test accuracy is 0.36666667461395264 and loss is 106.09306335449219\n"
     ]
    }
   ],
   "source": [
    "### Evaluation and prediction\n",
    "\n",
    "#Finally you can verify the performance of the model on new data using test set.\n",
    "\n",
    "loss1, accuracy1 = model.evaluate(test_dataset)\n",
    "print(\"The test accuracy is {} and loss is {}\".format(accuracy1, loss1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And now you are all set to use this model to predict if your pet is a normal or accident.\n",
    "\n",
    "# Retrieve a batch of images from the test set\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(15, 15))\n",
    "for i in range(60):\n",
    "  ax = plt.subplot(8, 8, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FE Epoch Undergo: \", initial_epochs)\n",
    "print(\"FT Epoch Undergo: \", earlystopping.stopped_epoch+1 - initial_epochs)\n",
    "print(\"Loss Percentage: %.2f\" % (loss1*100))\n",
    "print(\"Accuracy Percentage: %.2f\" % (accuracy1*100))\n",
    "print(\"Training Time %s seconds\" % (training_time))\n",
    "print(\"Correct Predictions out of 60: \", int(60*accuracy1))\n",
    "\n",
    "save_training_record(\"InceptionV3\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models_dir = os.path.join(main_dir, 'saved_models')\n",
    "#inception_model = os.path.join(models_dir, 'InceptionV3_2')\n",
    "#model.save(inception_model)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "NU-1tQQA2aCI",
    "outputId": "4aa332bb-c908-46dd-9fc6-e01ae55b72fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\65860\\Desktop\\SoftwareEngineering\\Year2\\ITP\\Project\\Traffic_ML\n",
      "train:  C:\\Users\\65860\\Desktop\\SoftwareEngineering\\Year2\\ITP\\Project\\Traffic_ML\\train\n",
      "Found 232 files belonging to 2 classes.\n",
      "Using 186 files for training.\n",
      "Found 232 files belonging to 2 classes.\n",
      "Using 46 files for validation.\n",
      "test:  C:\\Users\\65860\\Desktop\\SoftwareEngineering\\Year2\\ITP\\Project\\Traffic_ML\\test\n",
      "Found 59 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import lime\n",
    "import tensorflow.keras.preprocessing.image as tf_image\n",
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from skimage.io import imread\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "main_dir = os.path.normpath(os.getcwd() + os.sep + os.pardir)\n",
    "train_dir = os.path.join(main_dir, 'train')\n",
    "test_dir = os.path.join(main_dir, 'test')\n",
    "print(main_dir)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "print(\"train: \",train_dir)\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            validation_split=0.2,\n",
    "                                                            subset=\"training\",\n",
    "                                                            seed=123,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            image_size=IMG_SIZE)\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            validation_split=0.2,\n",
    "                                                            subset=\"validation\",\n",
    "                                                            seed=123,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            image_size=IMG_SIZE)\n",
    "\n",
    "print(\"test: \",test_dir)\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(test_dir,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "  for i in range(16):\n",
    "    ax = plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure the Dataset For Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "  tf.keras.layers.RandomFlip('horizontal'),\n",
    "  tf.keras.layers.RandomRotation(0.2),\n",
    "])\n",
    "\n",
    "for image, _ in train_dataset.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[0]\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescaling Pixel Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "def transform_img_fn(path_list):\n",
    "    out = []\n",
    "    for img_path in path_list:\n",
    "        img = tf_image.load_img(img_path, target_size=(224, 224))\n",
    "        x = tf_image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        out.append(x)\n",
    "    return np.vstack(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Base Model from MobileNet V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "#base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "#                                               include_top=True,\n",
    "#                                               weights='imagenet')\n",
    "\n",
    "model_file = os.path.join(os.getcwd(), 'saved_model.pb')\n",
    "print(model_file)\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(os.getcwd())\n",
    "print(\"Model loaded:\", loaded_model)\n",
    "\n",
    "#image_batch, label_batch = next(iter(train_dataset))\n",
    "#feature_batch = base_model(image_batch)\n",
    "#print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = loaded_model.predict_on_batch(image_batch).flatten()\n",
    "\n",
    "# Apply a sigmoid since our model returns logits\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = tf.where(predictions < 0.5, 0, 1)\n",
    "\n",
    "print('Predictions:\\n', predictions.numpy())\n",
    "print('Labels:\\n', label_batch)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(25):\n",
    "  ax = plt.subplot(5, 5, i + 1)\n",
    "  plt.imshow(image_batch[i].astype(\"uint8\"))\n",
    "  plt.title(class_names[predictions[i]])\n",
    "  plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os,sys\n",
    "try:\n",
    "    import lime\n",
    "except:\n",
    "    sys.path.append(os.path.join('..', '..')) # add the current directory\n",
    "    import lime\n",
    "from lime import lime_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model MobileNet V2\n",
    "\n",
    "#base_model_test = tf.keras.applications.MobileNetV2()\n",
    "\n",
    "#image_batch, label_batch = next(iter(train_dataset))\n",
    "#feature_batch = base_model(image_batch)\n",
    "#print(feature_batch.shape)\n",
    "\n",
    "#base_model_test = tf.keras.applications.MobileNetV2(weights='imagenet')\n",
    "\n",
    "Normal = os.path.join(test_dir, 'Accidents')\n",
    "print(Normal)\n",
    "img_test = os.path.join(Normal, 'accident_92.jpg')\n",
    "print(img_test)\n",
    "images = transform_img_fn([img_test])\n",
    "plt.imshow(images[0] / 2 + 0.5)\n",
    "#preds = loaded_model.predict(images)\n",
    "#for x in decode_predictions(preds, 10)[0]:\n",
    "#   print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime_image.LimeImageExplainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Hide color is the color for a superpixel turned OFF. Alternatively, if it is NONE, the superpixel will be replaced by the average of its pixels\n",
    "explanation = explainer.explain_instance(images[0].astype('double'), loaded_model.predict, top_labels=5, hide_color=0, num_samples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import mark_boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=True)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=5, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=10, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=1000, hide_rest=False, min_weight=0.1)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select the same class explained on the figures above.\n",
    "ind =  explanation.top_labels[0]\n",
    "\n",
    "#Map each explanation weight to the corresponding superpixel\n",
    "dict_heatmap = dict(explanation.local_exp[ind])\n",
    "heatmap = np.vectorize(dict_heatmap.get)(explanation.segments) \n",
    "\n",
    "#Plot. The visualization makes more sense if a symmetrical colorbar is used.\n",
    "plt.imshow(heatmap, cmap = 'RdBu', vmin  = -heatmap.max(), vmax = heatmap.max())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(0, positive_only=True, num_features=5, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp, mask = explanation.get_image_and_mask(867, positive_only=False, num_features=15, hide_rest=False)\n",
    "plt.imshow(mark_boundaries(temp / 2 + 0.5, mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0] / 2 + 0.5)\n",
    "preds = retrained_model.predict(images)\n",
    "for x in decode_predictions(preds, 10)[0]:\n",
    "   print(x)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled4.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
